/**
 * ××•×“×•×œ ×œ×ª××œ×•×œ ×§×‘×¦×™ ××•×“×™×• ×‘×××¦×¢×•×ª Huggingface ×•Groq
 * ×¢× ×˜×™×¤×•×œ ×‘×©×’×™××•×ª ××’×‘×œ×ª ×§×¦×‘ (Rate Limit)
 */
class Transcription {
    /**
     * ×ª××œ×•×œ ×§×•×‘×¥ ××•×“×™×• ×‘×•×“×“
     * @param {Blob} audioFile - ×§×•×‘×¥ ×”××•×“×™×• ×œ×ª××œ×•×œ
     * @param {string} apiKey - ××¤×ª×— ×”-API ×©×œ Huggingface ××• Groq
     * @param {string} provider - ×¡×¤×§ ×”×ª××œ×•×œ ('huggingface' ××• 'groq')
     * @returns {Promise<string>} - ×˜×§×¡×˜ ×”×ª××œ×•×œ
     */
    static async transcribeSingle(audioFile, apiKey, provider = 'huggingface') {
        // ××§×¨×” ××™×•×—×“ - ×ª×™×§×•×Ÿ MIME ×œ×¡×’×× ×˜ ×”×¨××©×•×Ÿ ×× ××“×•×‘×¨ ×‘-Groq
        if (provider === 'groq' && audioFile.name?.includes('segment_1')) {
            // × ×¡×” ×œ×©× ×•×ª ××ª ×¡×•×’ ×”-MIME (××¡×™×™×¢ ×œ×¤×¢××™×)
            audioFile = new File([audioFile], audioFile.name, {
                type: 'audio/mpeg',
                lastModified: Date.now()
            });
        }

        // ×©××™×¨×ª ×”××¤×ª×— ×•×”×¡×¤×§ ×”××§×•×¨×™×™× ×œ××§×¨×” ×©×œ ×©×’×™××” ×•××¢×‘×¨ ×œ×¡×¤×§ ××—×¨
        const originalProvider = provider;
        const originalApiKey = apiKey;

        try {
            // ×× ×”×¡×¤×§ ×”×•× Groq, × ×©×ª××© ×‘×¤×•× ×§×¦×™×” ×”×™×™×¢×•×“×™×ª ×œ×ª××œ×•×œ ×¢× Groq
            if (provider === 'groq') {
                try {
                    return await Transcription.transcribeWithGroq(audioFile, apiKey);
                } catch (groqError) {
                    // ×‘×“×™×§×” ×× ××“×•×‘×¨ ×‘×©×’×™××ª Rate Limit
                    if (groqError.message && 
                        (groqError.message.includes('rate_limit_exceeded') || 
                         groqError.message.includes('Rate limit reached'))) {
                        
                        console.warn('âš ï¸ ×”×ª×§×‘×œ×” ×©×’×™××ª Rate Limit ×-Groq, ×× ×¡×” ×œ×¢×‘×•×¨ ×œ-Huggingface:', groqError.message);
                        
                        // ×‘×“×™×§×” ×× ×™×© ××¤×ª×— API ×©×œ Huggingface ×–××™×Ÿ
                        const huggingfaceApiKey = localStorage.getItem('huggingface_api_key');
                        
                        if (huggingfaceApiKey) {
                            console.log('ğŸ”„ ×¢×•×‘×¨ ×œ×¡×¤×§ Huggingface');
                            // ××¢×‘×¨ ×œ-Huggingface ×‘××•×¤×Ÿ ×¨×§×•×¨×¡×™×‘×™ ×¢× ××•×ª×• ×§×•×‘×¥
                            return await Transcription.transcribeSingle(audioFile, huggingfaceApiKey, 'huggingface');
                        } else {
                            // ×× ××™×Ÿ ××¤×ª×— ×©×œ Huggingface, ×–×•×¨×§ ××ª ×”×©×’×™××” ×”××§×•×¨×™×ª ×¢× ×”×•×“×¢×” ×‘×¨×•×¨×” ×™×•×ª×¨
                            throw new Error('×”×’×¢×ª ×œ××’×‘×œ×ª ×”×§×¦×‘ ×©×œ Groq. × × ×œ×”××ª×™×Ÿ ××• ×œ×”×©×ª××© ×‘××¤×ª×— API ×©×œ Huggingface.');
                        }
                    } else {
                        // ×× ×–×• ×œ× ×©×’×™××ª Rate Limit, ×–×•×¨×§ ××ª ×”×©×’×™××” ×”××§×•×¨×™×ª
                        throw groqError;
                    }
                }
            }

            // ×‘×“×™×§×ª ××¤×ª×— API
            if (!apiKey) {
                throw new Error('××¤×ª×— API ×—×¡×¨');
            }

            // ×™×¦×™×¨×ª FormData ×œ×©×œ×™×—×ª ×”×§×•×‘×¥
            const formData = new FormData();

            // ×‘×“×™×§×” ×× ×”×§×•×‘×¥ ×”×•× ××¡×•×’ File ××• Blob
            if (audioFile instanceof File) {
                console.log(`×©×•×œ×— ×§×•×‘×¥: ${audioFile.name}, ×’×•×“×œ: ${audioFile.size} ×‘×ª×™×, ×¡×•×’: ${audioFile.type}`);
                formData.append('file', audioFile);
            } else if (audioFile instanceof Blob) {
                // ×™×¦×™×¨×ª ××•×‘×™×™×§×˜ File ××”-Blob
                const fileName = `audio_segment_${new Date().getTime()}.mp3`;
                const file = new File([audioFile], fileName, { type: 'audio/mpeg' });
                console.log(`×©×•×œ×— blob ×›×§×•×‘×¥: ${fileName}, ×’×•×“×œ: ${file.size} ×‘×ª×™×`);
                formData.append('file', file);
            } else {
                throw new Error('×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š');
            }

            // ×©×œ×™×—×ª ×”×§×•×‘×¥ ×œ-API ×©×œ Huggingface
            const response = await fetch(
                "https://api-inference.huggingface.co/models/openai/whisper-large-v3",
                {
                    method: "POST",
                    headers: {
                        "Authorization": `Bearer ${apiKey}`
                    },
                    body: formData
                }
            );

            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`×©×’×™××ª API (${response.status}): ${errorText}`);
            }

            const result = await response.json();
            return result.text || '';

        } catch (error) {
            console.error('Error in transcription:', error);
            
            // × ×™×¡×™×•×Ÿ ×œ×”×—×œ×¤×ª ×¡×¤×§ ×‘××§×¨×” ×©×œ ×©×’×™××”
            if (originalProvider === 'huggingface' && error.message.includes('503')) {
                // ×× ×”×©×’×™××” ×”×™× ×-Huggingface ×•×”×™× 503 (×©×™×¨×•×ª ×œ× ×–××™×Ÿ), × × ×¡×” ×œ×¢×‘×•×¨ ×œ-Groq
                const groqApiKey = localStorage.getItem('groq_api_key');
                
                if (groqApiKey) {
                    console.warn('âš ï¸ Huggingface ××—×–×™×¨ ×©×’×™××”, ×× ×¡×” ×œ×¢×‘×•×¨ ×œ-Groq');
                    return await Transcription.transcribeSingle(audioFile, groqApiKey, 'groq');
                }
            }
            
            // ×× ×œ× ×”×¦×œ×—× ×• ×œ×”×—×œ×™×£ ×¡×¤×§ ××• ×©×”×™×ª×” ×©×’×™××” ××—×¨×ª, × ×–×¨×•×§ ××ª ×”×©×’×™××” ×”××§×•×¨×™×ª
            throw error;
        }
    }

    /**
     * ×ª××œ×•×œ ××¡×¤×¨ ×§×˜×¢×™× ×©×œ ××•×“×™×• ×‘××•×¤×Ÿ ××§×‘×™×œ×™
     * @param {Blob[]} audioSegments - ××¢×¨×š ×©×œ ×§×˜×¢×™ ××•×“×™×•
     * @param {string} apiKey - ××¤×ª×— ×”-API ×©×œ Huggingface/Groq
     * @param {Function} onProgress - ×¤×•× ×§×¦×™×™×ª callback ×œ×¢×“×›×•×Ÿ ×”×ª×§×“××•×ª
     * @param {number} maxConcurrent - ××¡×¤×¨ ××§×¡×™××œ×™ ×©×œ ×‘×§×©×•×ª ×‘××§×‘×™×œ
     * @param {string} provider - ×¡×¤×§ ×”×ª××œ×•×œ ('huggingface' ××• 'groq')
     * @returns {Promise<string>} - ×˜×§×¡×˜ ×”×ª××œ×•×œ ×”××œ×
     */
    static async transcribeSegments(audioSegments, apiKey, onProgress = null, maxConcurrent = 2, provider = 'groq') {
        if (!apiKey) {
            throw new Error('××¤×ª×— API ×—×¡×¨');
        }

        if (!audioSegments || audioSegments.length === 0) {
            return '';
        }

        console.log(`××ª×—×™×œ ×ª××œ×•×œ ${audioSegments.length} ×§×˜×¢×™× ×¢× ×¡×¤×§: ${provider}`);

        // ××¢×¨×š ×©×™×›×™×œ ××ª ×›×œ ×”×ª×•×¦××•×ª
        const results = new Array(audioSegments.length);
        let completedSegments = 0;

        // ×©××™×¨×ª ×”×¡×¤×§ ×•×”××¤×ª×— ×”××§×•×¨×™×™× (×‘××§×¨×” ×©× ×¦×˜×¨×š ×œ×”×—×œ×™×£ ×‘×××¦×¢)
        const originalProvider = provider;
        const originalApiKey = apiKey;

        // ××¤×ª×— API ××œ×˜×¨× ×˜×™×‘×™ ×‘××§×¨×” ×©× ×’×™×¢ ×œ××’×‘×œ×ª ×§×¦×‘
        let alternativeProvider = provider === 'groq' ? 'huggingface' : 'groq';
        let alternativeApiKey = localStorage.getItem(
            alternativeProvider === 'groq' ? 'groq_api_key' : 'huggingface_api_key'
        );

        // ××©×ª× ×” ×©×¢×•×§×‘ ××—×¨×™ ×× ×¢×‘×¨× ×• ×œ×¡×¤×§ ××—×¨ ×‘××”×œ×š ×”×ª××œ×•×œ
        let switchedProvider = false;

        // ×¤×•× ×§×¦×™×” ×œ×¢×™×‘×•×“ ×§×˜×¢ ×‘×•×“×“
        async function processSegment(index) {
            try {
                const segment = audioSegments[index];

                // ×‘×“×™×§×” ×× ×”×§×˜×¢ ×ª×§×£
                const isValid = await Transcription.isAudioFileValid(segment);
                if (!isValid) {
                    console.warn(`âš ï¸ ×§×˜×¢ ${index + 1} ×œ× ×ª×§×™×Ÿ â€“ ×™×™×ª×›×Ÿ ×©×”×•× ×§×¦×¨ ××“×™ ××• ×©×§×˜`);
                    results[index] = `[×§×˜×¢ ${index + 1} ×–×•×”×” ×›×œ× ×ª×§×™×Ÿ]`;
                    completedSegments++;
                    return;
                }

                console.log(`××ª××œ×œ ×§×˜×¢ ${index + 1}/${audioSegments.length} ×¢× ×¡×¤×§: ${switchedProvider ? alternativeProvider : originalProvider}`);

                // ×‘×—×™×¨×ª ×”×¡×¤×§ ×•×”××¤×ª×— ×”× ×›×•× ×™× (×”××§×•×¨×™×™× ××• ×”××œ×˜×¨× ×˜×™×‘×™×™×)
                const currentProvider = switchedProvider ? alternativeProvider : originalProvider;
                const currentApiKey = switchedProvider ? alternativeApiKey : originalApiKey;

                try {
                    // × ×™×¡×™×•×Ÿ ×ª××œ×•×œ ×¨×’×™×œ
                    const transcription = await Transcription.transcribeSingle(segment, currentApiKey, currentProvider);
                    console.log(`âœ… ×§×˜×¢ ${index + 1} ×ª×•××œ×œ ×‘×”×¦×œ×—×”`);

                    // ×©××™×¨×ª ×”×ª×•×¦××”
                    results[index] = transcription;
                    completedSegments++;

                    if (onProgress) {
                        onProgress({
                            status: 'transcribing',
                            progress: (completedSegments / audioSegments.length) * 100,
                            completedSegments,
                            totalSegments: audioSegments.length,
                            currentSegmentIndex: index
                        });
                    }

                    return transcription;
                } catch (error) {
                    // ×‘×“×™×§×” ×× ××“×•×‘×¨ ×‘×©×’×™××ª Rate Limit ×•×™×© ××¤×©×¨×•×ª ×œ×¢×‘×•×¨ ×œ×¡×¤×§ ××—×¨
                    if (!switchedProvider && 
                        alternativeApiKey && 
                        (error.message.includes('rate_limit_exceeded') || 
                         error.message.includes('Rate limit reached'))) {
                        
                        console.warn(`âš ï¸ ×”×ª×§×‘×œ×” ×©×’×™××ª Rate Limit ×-${currentProvider}, ×¢×•×‘×¨ ×œ-${alternativeProvider}`);
                        switchedProvider = true;
                        
                        // × ×™×¡×™×•×Ÿ ×—×•×–×¨ ×¢× ×”×¡×¤×§ ×”××œ×˜×¨× ×˜×™×‘×™
                        const transcription = await Transcription.transcribeSingle(segment, alternativeApiKey, alternativeProvider);
                        console.log(`âœ… ×§×˜×¢ ${index + 1} ×ª×•××œ×œ ×‘×”×¦×œ×—×” ×¢× ${alternativeProvider}`);
                        
                        // ×©××™×¨×ª ×”×ª×•×¦××”
                        results[index] = transcription;
                        completedSegments++;
                        
                        if (onProgress) {
                            onProgress({
                                status: 'transcribing',
                                progress: (completedSegments / audioSegments.length) * 100,
                                completedSegments,
                                totalSegments: audioSegments.length,
                                currentSegmentIndex: index,
                                providerSwitched: true,
                                newProvider: alternativeProvider
                            });
                        }
                        
                        return transcription;
                    }
                    
                    // ×× ××™×Ÿ ××¤×©×¨×•×ª ×œ×¢×‘×•×¨ ×œ×¡×¤×§ ××—×¨ ××• ×©×–×• ×©×’×™××” ××—×¨×ª, × ×˜×¤×œ ×‘×§×˜×¢ ×”×¨××©×•×Ÿ ×‘××•×¤×Ÿ ××™×•×—×“
                    if (index === 0 && currentProvider === 'groq') {
                        console.log(`âš ï¸ × ×™×¡×™×•×Ÿ ×ª××œ×•×œ ×§×˜×¢ ×¨××©×•×Ÿ × ×›×©×œ. ××¤×¢×™×œ ×˜×™×¤×•×œ ××™×•×—×“...`);
                        
                        // × ×™×¡×™×•×Ÿ ×©× ×™ - ×©×™× ×•×™ ×¡×•×’ MIME
                        try {
                            console.log(`ğŸ”„ × ×™×¡×™×•×Ÿ 2: ×©×™× ×•×™ ×¡×•×’ MIME ×œ×§×˜×¢ ×¨××©×•×Ÿ...`);
                            
                            const mimeFixedSegment = new File([segment], segment.name, {
                                type: 'audio/mpeg',
                                lastModified: Date.now()
                            });
                            
                            const transcription = await Transcription.transcribeSingle(mimeFixedSegment, currentApiKey, currentProvider);
                            console.log(`âœ… ×§×˜×¢ ×¨××©×•×Ÿ ×ª×•××œ×œ ×‘×”×¦×œ×—×” ×œ××—×¨ ×ª×™×§×•×Ÿ MIME`);
                            
                            // ×©××™×¨×ª ×”×ª×•×¦××”
                            results[index] = transcription;
                            completedSegments++;
                            
                            if (onProgress) {
                                onProgress({
                                    status: 'transcribing',
                                    progress: (completedSegments / audioSegments.length) * 100,
                                    completedSegments,
                                    totalSegments: audioSegments.length,
                                    currentSegmentIndex: index
                                });
                            }
                            
                            return transcription;
                        } catch (secondError) {
                            // × ×™×¡×™×•×Ÿ ×©×œ×™×©×™ - ×—×™×ª×•×š ××—×“×©
                            try {
                                console.log(`âš ï¸ ×’× × ×™×¡×™×•×Ÿ 2 × ×›×©×œ. ×× ×¡×” × ×™×¡×™×•×Ÿ 3: ×—×™×ª×•×š ××—×“×©...`);
                                
                                const fixedSegment = await AudioSplitter.handleFirstSegment(segment, 25);
                                const finalSegment = new File([fixedSegment], fixedSegment.name, {
                                    type: 'audio/mpeg',
                                    lastModified: Date.now()
                                });
                                
                                const transcription = await Transcription.transcribeSingle(finalSegment, currentApiKey, currentProvider);
                                console.log(`âœ… ×§×˜×¢ ×¨××©×•×Ÿ ×ª×•××œ×œ ×‘×”×¦×œ×—×” ×œ××—×¨ ×—×™×ª×•×š ××—×“×©!`);
                                
                                // ×©××™×¨×ª ×”×ª×•×¦××”
                                results[index] = transcription;
                                completedSegments++;
                                
                                if (onProgress) {
                                    onProgress({
                                        status: 'transcribing',
                                        progress: (completedSegments / audioSegments.length) * 100,
                                        completedSegments,
                                        totalSegments: audioSegments.length,
                                        currentSegmentIndex: index
                                    });
                                }
                                
                                return transcription;
                            } catch (thirdError) {
                                console.error(`âŒ ×›×œ ×”× ×™×¡×™×•× ×•×ª × ×›×©×œ×• ×œ×§×˜×¢ ${index + 1}:`, thirdError.message);
                                throw thirdError;
                            }
                        }
                    } else {
                        // ×× ×–×” ×œ× ×”×§×˜×¢ ×”×¨××©×•×Ÿ ××• ×©××“×•×‘×¨ ×‘-Huggingface, ×¤×©×•×˜ ×–×•×¨×§ ××ª ×”×©×’×™××”
                        throw error;
                    }
                }
            } catch (error) {
                console.error(`Error transcribing segment ${index + 1}:`, error);
                
                // ×× ×œ× ×”×¦×œ×—× ×• ×œ×ª××œ×œ, × ×©××•×¨ ×”×•×“×¢×ª ×©×’×™××” ×›×ª×•×¦××”
                results[index] = `[×©×’×™××” ×‘×ª××œ×•×œ ×§×˜×¢ ${index + 1}: ${error.message}]`;
                
                // ×¢×“×›×•×Ÿ ×”×”×ª×§×“××•×ª ×’× ×‘××§×¨×” ×©×œ ×©×’×™××”
                completedSegments++;
                if (onProgress) {
                    onProgress({
                        status: 'error',
                        progress: (completedSegments / audioSegments.length) * 100,
                        completedSegments,
                        totalSegments: audioSegments.length,
                        currentSegmentIndex: index,
                        error: error.message
                    });
                }
                
                throw error;
            }
        }

        // ×¢×™×‘×•×“ ×§×˜×¢×™× ×‘×§×‘×•×¦×•×ª ××§×‘×™×œ×•×ª
        async function processInBatches() {
            const totalSegments = audioSegments.length;
            
            // ×¢×™×‘×•×“ ×‘×§×‘×•×¦×•×ª ×©×œ maxConcurrent ×§×˜×¢×™×
            for (let i = 0; i < totalSegments; i += maxConcurrent) {
                const batchPromises = [];
                
                // ×™×¦×™×¨×ª Promise ×œ×›×œ ×§×˜×¢ ×‘×§×‘×•×¦×” ×”× ×•×›×—×™×ª
                for (let j = 0; j < maxConcurrent && i + j < totalSegments; j++) {
                    batchPromises.push(processSegment(i + j).catch(error => {
                        // ×œ×›×™×“×ª ×©×’×™××•×ª ×›×“×™ ×©×”×§×‘×•×¦×” ×ª××©×™×š ×’× ×× ×§×˜×¢ ××—×“ × ×›×©×œ
                        console.error(`Batch processing error for segment ${i + j}:`, error);
                        return `[×©×’×™××” ×‘×ª××œ×•×œ]`;
                    }));
                }
                
                // ×”××ª× ×” ×œ×¡×™×•× ×”×§×‘×•×¦×” ×”× ×•×›×—×™×ª ×œ×¤× ×™ ×”××¢×‘×¨ ×œ×§×‘×•×¦×” ×”×‘××”
                await Promise.allSettled(batchPromises);
                
                // ×¢×™×›×•×‘ ×§×˜×Ÿ ×‘×™×Ÿ ×§×‘×•×¦×•×ª ×›×“×™ ×œ× ×œ×”×¢××™×¡ ×¢×œ ×”-API
                if (i + maxConcurrent < totalSegments) {
                    await new Promise(resolve => setTimeout(resolve, 500));
                }
            }
        }

        // ×¢×™×‘×•×“ ×›×œ ×”×§×˜×¢×™× ×‘×§×‘×•×¦×•×ª
        await processInBatches();
        
        // ×‘×“×™×§×ª ×©×œ××•×ª ×”×ª×•×¦××•×ª
        for (let i = 0; i < audioSegments.length; i++) {
            if (!results[i]) {
                results[i] = `[×œ× ×”×ª×§×‘×œ ×ª××œ×•×œ ×œ×§×˜×¢ ${i + 1}]`;
            }
        }
        
        // ×—×™×‘×•×¨ ×›×œ ×”×ª×•×¦××•×ª ×œ×˜×§×¡×˜ ××—×“
        return results.join(' ');
    }

    /**
     * ×ª××œ×•×œ ×‘×××¦×¢×•×ª Groq API
     * @param {File|Blob} audioFile - ×§×•×‘×¥ ×”××•×“×™×• ×œ×ª××œ×•×œ
     * @param {string} apiKey - ××¤×ª×— ×”-API ×©×œ Groq
     * @returns {Promise<string>} - ×˜×§×¡×˜ ×”×ª××œ×•×œ
     */
    static async transcribeWithGroq(audioFile, apiKey) {
        if (!apiKey) throw new Error('××¤×ª×— API ×©×œ Groq ×—×¡×¨');
        
        // ×™×¦×™×¨×ª ××•×‘×™×™×§×˜ File ×× ×¦×¨×™×š
        let fileToSend;
        if (audioFile instanceof File) {
            fileToSend = audioFile;
        } else if (audioFile instanceof Blob) {
            fileToSend = new File([audioFile], `audio_${Date.now()}.mp3`, { type: 'audio/mpeg' });
        } else {
            throw new Error("×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š");
        }
        
        // ×”×›× ×ª × ×ª×•× ×™ ×”×‘×§×©×”
        const formData = new FormData();
        formData.append("file", fileToSend);
        formData.append("model", "whisper-large-v3");
        formData.append("language", "he"); // ×¢×‘×¨×™×ª
        formData.append("response_format", "text"); // ×¨×§ ×”×˜×§×¡×˜, ×‘×œ×™ JSON ××™×•×ª×¨
        
        try {
            const response = await fetch("https://api.groq.com/openai/v1/audio/transcriptions", {
                method: "POST",
                headers: {
                    "Authorization": `Bearer ${apiKey}`
                },
                body: formData
            });
            
            // ×˜×™×¤×•×œ ×‘×©×’×™××•×ª HTTP
            if (!response.ok) {
                const contentType = response.headers.get('content-type');
                
                // ×˜×™×¤×•×œ ×‘×ª×©×•×‘×•×ª JSON (×¢× ×¤×™×¨×•×˜ ×”×©×’×™××”)
                if (contentType && contentType.includes('application/json')) {
                    const errorJson = await response.json();
                    
                    // ×‘×“×™×§×” ×œ×©×’×™××•×ª Rate Limit ×¡×¤×¦×™×¤×™×•×ª
                    if (errorJson.error && (
                        errorJson.error.code === 'rate_limit_exceeded' || 
                        errorJson.error.message?.includes('Rate limit') ||
                        errorJson.error.type === 'rate_limit_exceeded'
                    )) {
                        throw new Error(`rate_limit_exceeded: ${errorJson.error.message || '×”×’×¢×ª ×œ××’×‘×œ×ª ×§×¦×‘ ×©×œ Groq'}`);
                    }
                    
                    throw new Error(`×©×’×™××ª API (${response.status}): ${JSON.stringify(errorJson.error)}`);
                } 
                
                // ×˜×™×¤×•×œ ×‘×©×’×™××•×ª ×˜×§×¡×˜ ×¨×’×™×œ
                const errorText = await response.text();
                throw new Error(`×©×’×™××ª API (${response.status}): ${errorText}`);
            }
            
            // ×§×‘×œ×ª ×”×ª×•×¦××”
            const text = await response.text(); // ×›×™ ×‘×™×§×©× ×• `response_format: text`
            return text.trim();
            
        } catch (error) {
            // ×‘×“×™×§×” ×œ×©×’×™××•×ª Rate Limit ×¡×¤×¦×™×¤×™×•×ª ×©×œ× × ×ª×¤×¡×• ×§×•×“×
            if (error.message && (
                error.message.includes('rate_limit_exceeded') || 
                error.message.includes('Rate limit')
            )) {
                console.error('Rate limit error from Groq:', error.message);
                throw new Error(`rate_limit_exceeded: ${error.message}`);
            }
            
            throw error;
        }
    }

    /**
     * ×‘×“×™×§×ª ×ª×§×™× ×•×ª ×©×œ ×§×•×‘×¥ ××•×“×™×•
     * @param {File|Blob} audioFile - ×§×•×‘×¥ ×”××•×“×™×• ×œ×‘×“×™×§×”
     * @returns {Promise<boolean>} - ×”×× ×”×§×•×‘×¥ ×ª×§×™×Ÿ
     */
    static async isAudioFileValid(audioFile) {
        return new Promise((resolve) => {
            try {
                const audio = new Audio();
                
                audio.oncanplay = () => {
                    URL.revokeObjectURL(audio.src);
                    resolve(true);
                };
                
                audio.onerror = () => {
                    URL.revokeObjectURL(audio.src);
                    resolve(false);
                };
                
                // ×˜×™×™××××•×˜ ×œ××§×¨×” ×©××™×Ÿ ×ª×’×•×‘×”
                const timeout = setTimeout(() => {
                    URL.revokeObjectURL(audio.src);
                    resolve(false);
                }, 5000);
                
                audio.oncanplay = () => {
                    clearTimeout(timeout);
                    URL.revokeObjectURL(audio.src);
                    resolve(true);
                };
                
                audio.src = URL.createObjectURL(audioFile);
                audio.load();
            } catch (error) {
                console.error('Error validating audio file:', error);
                resolve(false);
            }
        });
    }
}

// ×™×™×¦×•× ×”××•×“×•×œ
window.Transcription = Transcription;